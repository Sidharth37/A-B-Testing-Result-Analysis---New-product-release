# A-B-Testing-Result-Analysis---New-product-release

A/B testing is the process of comparing 2 versions of the same asset, and evaluating the difference in performance. It is used everywhere from thumbnails in Netflix, to new product releases on Amazon, to display of search results on Google. But once the results are obtained it becomes equally important to understand if the difference in results are statistically significant or was it a random occurences that took place because of particular samples being selected by chance. In this project we will compare 3 such promotions carried across different of varying sizes across locations and understand if 1 promotional campaign is better than the other, and help the firm decide on a marketing strategy for it's newly released product.<br><br>

<b>The project is divided in 2 main parts -</b><br>
1. Data Ingestion, Exploratory Data Analysis & Data Visualization
2. Implementing statistical tests to evaluate the merit of promotional campaigns against each other
<br><br>
<b>Data Ingestion, Exploratory Data Analysis & Data Visualization</b>
The data was ingested using an xlsx file.<br>
Based on initial exploration we collect the following information -<br>
The promotions were run across 137 distinct locations<br>
These campaigns were run across both old and new stores<br>
The largest sales recorded was due to Promotional campaign 3, followed by promotional campaign 1, followed by promotional campaign 2.<br>
All 3 market sizes namely - large, medium and small participated in these campaigns<br>
Predominantly medium market sizes were used to run all the 3 campaigns<br>
Also there seems to be a preference for newer store as compared to older stores<br>

